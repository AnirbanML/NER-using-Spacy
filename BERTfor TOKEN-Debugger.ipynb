{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23a416b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/mmortgage/NERAPI/NER/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-10-14 08:44:22.795446: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-14 08:44:22.973592: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-14 08:44:23.686890: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-14 08:44:23.687008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-10-14 08:44:23.687021: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertConfig\n",
    "\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.metrics import accuracy_score, f1_score\n",
    "import transformers\n",
    "from transformers import BertForTokenClassification, AdamW, BertModel\n",
    "from seqeval.metrics import f1_score, accuracy_score\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "import numpy as np\n",
    "\n",
    "import glob\n",
    "import random\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from pathlib import Path\n",
    "import json\n",
    "import string\n",
    "import numpy as np\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11a46556",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'PAD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0792d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd2f3c61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"bert-base-cased\",\n",
    "    num_labels=len(entities),\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01338317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"/mnt/BERT_NER/BERT_epoch10.model\", map_location=torch.device('cuda')))\n",
    "model.cuda()\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac696f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09600f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_dir = r\"/data/mmortgage/amal_workspace/BankStatement_Failed/pdf_ld\"\n",
    "ocr_dir = r\"/data/mmortgage/amal_workspace/BankStatement_Failed/ocr_ld\"\n",
    "img_dir = r\"/data/mmortgage/amal_workspace/BankStatement_Failed/images\"\n",
    "text_dir = r\"/data/mmortgage/amal_workspace/BankStatement_Failed/text\"\n",
    "image_bb = \"/mnt/NER/bb_images/11_10_22_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfa0ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf in Path(pdf_dir).glob('**/*.pdf'):\n",
    "# for i, row in df.iterrows():\n",
    "#     pdf = f\"{row[0]}.pdf\"\n",
    "    out = Path(img_dir)/Path(pdf).stem\n",
    "    if not out.exists():\n",
    "        out.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    convert_from_path(Path(pdf_dir)/Path(pdf), fmt=\"jpg\",\n",
    "                     output_folder=out,\n",
    "                     output_file=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04158317",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image):\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832d5cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_inch(aref, bref, value):\n",
    "    \"\"\"\n",
    "\n",
    "    :param aref: reference in inches\n",
    "    :param bref: reference in pixel\n",
    "    :param value: in pixel\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    return round((aref * value) / bref, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42d9598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_intersection_over_union(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = abs((boxA[2] - boxA[0]) * (boxA[3] - boxA[1]))\n",
    "    boxBArea = abs((boxB[2] - boxB[0] ) * (boxB[3] - boxB[1]))\n",
    "    \n",
    "    smallerBB_area = boxB if boxAArea>boxBArea else boxA\n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea) #+ 1e-6\n",
    "    # return the intersection over union value\n",
    "    return iou, smallerBB_area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0db067",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_text_ttb(adr, page_no):\n",
    "    zeroes = \"0\" * (len(str(len(list((Path(img_dir)/Path(adr)).glob('**/*.jpg')))))-1)\n",
    "    image_path = str(Path(img_dir)/Path(adr)/Path(f\"0001-{zeroes}{page_no}.jpg\"))\n",
    "    print(image_path)\n",
    "    ocr_path = str(Path(ocr_dir)/Path(f\"{adr}.txt\"))\n",
    "    image = cv2.imread(image_path)\n",
    "#     print(image)\n",
    "    height_px, width_px, _ = image.shape\n",
    "    \n",
    "    gry_img =  cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    smoothing = cv2.bilateralFilter(gry_img, 15, 75, 75)\n",
    "    kernel_sharpen = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpen = cv2.filter2D(smoothing, -1, kernel_sharpen)\n",
    "    \n",
    "    bw = cv2.threshold(sharpen, 160, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)[1]\n",
    "    \n",
    "    kernel_dil = np.ones((3,3), np.uint8)\n",
    "    img_dilation = cv2.dilate(bw, kernel_dil, iterations=10)\n",
    "    \n",
    "    img_edges = cv2.Canny(img_dilation, 0, 10, apertureSize=3, L2gradient = True)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(img_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "    \n",
    "#     imContour = image.copy()\n",
    "#     imContour = cv2.drawContours(imContour, contours, -1, (0, 255, 0), 2)\n",
    "    \n",
    "    boxes=[]\n",
    "\n",
    "#     imRect1 = image.copy()\n",
    "    for i,cnt in enumerate(contours): \n",
    "        (x, y, w, h) = cv2.boundingRect(cnt)\n",
    "        #if w>100 and w<300 and h>50 and h<150:\n",
    "        boxes.append([x, y, x+w, y+h])\n",
    "#         cv2.rectangle(imRect1, (x,y), (x+w,y+h), (255, 0, 0), 2)\n",
    "        \n",
    "    n = len(boxes)\n",
    "    l_iou = []\n",
    "    final_boxes = boxes.copy()\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            iou, rem = bb_intersection_over_union(boxes[i], boxes[j])\n",
    "    #         iou = round(iou,3)\n",
    "            l_iou.append(iou)\n",
    "            if iou>0:\n",
    "                if rem in final_boxes:\n",
    "                    final_boxes.remove(rem)\n",
    "                    \n",
    "    imRect = image.copy()\n",
    "    for x1,y1,x2,y2 in final_boxes: \n",
    "        cv2.rectangle(imRect, (x1,y1), (x2,y2), (255, 0, 0), 2)\n",
    "        \n",
    "    filename = str(Path(image_bb)/ Path(Path(image_path).parent.stem+\"_\"+Path(image_path).stem))+\".jpg\"\n",
    "    cv2.imwrite(filename, imRect)\n",
    "    \n",
    "    sorted_cords = sorted(final_boxes , key=lambda k: [k[1], k[0]])\n",
    "    \n",
    "    with open(ocr_path, \"r\") as f:\n",
    "        ocr = json.load(f)\n",
    "\n",
    "    page_text = []\n",
    "    for page in ocr[\"analyzeResult\"][\"readResults\"]:\n",
    "        if page[\"page\"]==page_no:\n",
    "    #     l = page[\"lines\"]  # boundingBox\n",
    "    #     print(page[\"page\"])\n",
    "            ocr_cords_sort = sorted(page[\"lines\"] , key=lambda k: [k[\"boundingBox\"][1], k[\"boundingBox\"][0]])\n",
    "#             print(\"before\", len(ocr_cords_sort))\n",
    "\n",
    "            height_inch, width_inch = page[\"height\"], page[\"width\"]\n",
    "            text_lst = []\n",
    "            for bb in sorted_cords:\n",
    "                rem_index = []\n",
    "                for i,v in enumerate(ocr_cords_sort):\n",
    "                    bb_tl_x = pixel_to_inch(width_inch, width_px, bb[0])\n",
    "                    bb_tl_y = pixel_to_inch(height_inch, height_px, bb[1])\n",
    "                    bb_br_x = pixel_to_inch(width_inch, width_px, bb[2])\n",
    "                    bb_br_y = pixel_to_inch(height_inch, height_px, bb[3])\n",
    "                    if bb_tl_x<=v[\"boundingBox\"][0]<=bb_br_x and bb_tl_y<=v[\"boundingBox\"][1]<=bb_br_y:\n",
    "                        text_lst.append(v[\"text\"])\n",
    "                        rem_index.append(i)\n",
    "        #                 break\n",
    "        #         print(rem_index)\n",
    "                if rem_index:            \n",
    "                    for index in sorted(rem_index, reverse=True):\n",
    "                        del ocr_cords_sort[index]\n",
    "\n",
    "            #         break\n",
    "#             print(\"after\", len(ocr_cords_sort))\n",
    "            if ocr_cords_sort:\n",
    "                for t in ocr_cords_sort:\n",
    "                    text_lst.append(t[\"text\"])\n",
    "\n",
    "#             break  \n",
    "            return \" \".join(text_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fad063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = Path(img_dir)\n",
    "# for adr in [f for f in p.iterdir() if f.is_dir()]:\n",
    "#     page_no = 1\n",
    "#     text = gen_text_ttb(adr.stem, page_no)\n",
    "#     with open(f'{text_dir}/{adr.stem}_{page_no}.txt', 'w') as f:\n",
    "#         f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a54cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr = \n",
    "page_no = 1\n",
    "test_sentence = gen_text_ttb(adr.stem, page_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d1a78a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentence = \"\"\"\n",
    "BANK OF AMERICA Preferred Rewards BANK OF AMERICA P.O. Box 15284 Wilmington, DE 19850 Customer service information 1.888.888.RWDS (1.888.888.7937) En EspaÃ±ol: 1.800.688.6086 ERIK M LITTLE 4253 CORINTH CHURCH RD LAKE PARK, GA 31636-2923 bankofamerica.com Bank of America, N.A. P.O. Box 25118 Tampa, FL 33622-5118 Your Regular Checking Preferred Rewards Platinum for July 16, 2022 to August 17, 2022 Account number: 3340 2555 6556 ERIK M LITTLE ATM and debit card subtractions -0.00 Other subtractions -1,470.00 Checks -0.00 Service fees -0.00 $126.78 Ending balance on August 17, 2022 Do you follow us on social media? Connect with us on Facebook and Twitter for timely information and to learn more about how to reach your financial goals. f When you use the QRC feature certain information is collected from your mobile device for business purposes. SSM-05-22-0100ÄŒ | 4718133 Page 1 of 4 CYCLE: 10 SPEC: E IMAGE: I BC: GA PULL: B DELIVERY: E TYPE: Account summary $392.14 Beginning balance on July 16, 2022 Deposits and other additions 1,204.64\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b8d4708",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_sentence = tokenizer.encode(test_sentence, add_special_tokens=False)\n",
    "input_ids = torch.tensor([tokenized_sentence[:300]]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cda71286",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_ids)\n",
    "label_indices = np.argmax(output[0].to('cpu').numpy(), axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e308693",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tag_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     new_tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m new_tokens[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m+\u001b[39m token[\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 8\u001b[0m     new_labels\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtag_values\u001b[49m[label_idx])\n\u001b[1;32m      9\u001b[0m     new_tokens\u001b[38;5;241m.\u001b[39mappend(token)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tag_values' is not defined"
     ]
    }
   ],
   "source": [
    "# join bpe split tokens\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.to('cpu').numpy()[0])\n",
    "new_tokens, new_labels = [], []\n",
    "for token, label_idx in zip(tokens, label_indices[0]):\n",
    "    if token.startswith(\"##\"):\n",
    "        new_tokens[-1] = new_tokens[-1] + token[2:]\n",
    "    else:\n",
    "        new_labels.append(tag_values[label_idx])\n",
    "        new_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6b8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, label in zip(new_tokens, new_labels):\n",
    "    print(\"{}\\t{}\".format(label, token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b636c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {\"PER\":[], \"ORG\": [], \"LOC\":[]}\n",
    "for i, (token, label) in enumerate(zip(new_tokens, new_labels)):\n",
    "    if label == \"B-ORG\":\n",
    "        e = token\n",
    "        i_n = i + 1\n",
    "        while new_labels[i_n] == \"I-ORG\":\n",
    "            e = e+\" \"+new_tokens[i_n]\n",
    "            i_n += 1\n",
    "        \n",
    "        if new_labels[i+1]!=\"I-ORG\":\n",
    "            continue\n",
    "        d[\"ORG\"].append(e)\n",
    "        e = \"\"\n",
    "        continue\n",
    "        \n",
    "    if label == \"B-PER\":\n",
    "        e = token\n",
    "        i_n = i + 1\n",
    "        while new_labels[i_n] == \"I-PER\":\n",
    "            e = e+\" \"+new_tokens[i_n]\n",
    "            i_n += 1\n",
    "        \n",
    "        if new_labels[i+1]!=\"I-PER\":\n",
    "            continue\n",
    "        d[\"PER\"].append(e)\n",
    "        e = \"\"\n",
    "        continue\n",
    "    \n",
    "    if label == \"B-LOC\":\n",
    "        e = token\n",
    "        i_n = i + 1\n",
    "        while new_labels[i_n] == \"I-LOC\":\n",
    "            e = e+\" \"+new_tokens[i_n]\n",
    "            i_n += 1\n",
    "        \n",
    "        if new_labels[i+1]!=\"I-LOC\":\n",
    "            continue\n",
    "        d[\"LOC\"].append(e)\n",
    "        e = \"\"\n",
    "        continue   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feb4d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NER",
   "language": "python",
   "name": "ner"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
